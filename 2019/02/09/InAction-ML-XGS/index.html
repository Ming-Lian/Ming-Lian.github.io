<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用1.1. 任务描述具体任务可以到 ‘达观杯’文本智能处理挑战赛官网 查看 任务：建立模型通过长文本数据正文(article)，预测文本对应的类别(class) 数据：  数据包含2个csv文件：  train_set.csv   此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共">
<meta name="keywords" content="sklearn,logistic回归,决策树,朴素贝叶斯方法">
<meta property="og:type" content="article">
<meta property="og:title" content="西瓜书带学训练营·实战任务">
<meta property="og:url" content="http://yoursite.com/2019/02/09/InAction-ML-XGS/index.html">
<meta property="og:site_name" content="Lianm&#39;s Blog">
<meta property="og:description" content="1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用1.1. 任务描述具体任务可以到 ‘达观杯’文本智能处理挑战赛官网 查看 任务：建立模型通过长文本数据正文(article)，预测文本对应的类别(class) 数据：  数据包含2个csv文件：  train_set.csv   此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-1.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-2.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-3.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-4.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-5.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-6.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-7.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-decision-tree-1.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-decision-tree-2.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-1.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-2.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-3.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-4.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-5.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-6.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-7.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-8.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-9.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-10.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-11.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-12.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-13.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-SVM-14.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-1.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-2.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-3.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-4.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-5.png">
<meta property="og:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-6.png">
<meta property="og:updated_time" content="2019-02-24T14:23:38.833Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="西瓜书带学训练营·实战任务">
<meta name="twitter:description" content="1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用1.1. 任务描述具体任务可以到 ‘达观杯’文本智能处理挑战赛官网 查看 任务：建立模型通过长文本数据正文(article)，预测文本对应的类别(class) 数据：  数据包含2个csv文件：  train_set.csv   此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共">
<meta name="twitter:image" content="http://yoursite.com/images/InAction-MachineLearning-XGS-sklearn-lr-1.png">






  <link rel="canonical" href="http://yoursite.com/2019/02/09/InAction-ML-XGS/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>西瓜书带学训练营·实战任务 | Lianm's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Lianm's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Focus on Bioinformatics and Machine-Learning</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    
  
  
  
  

  

  <a href="https://github.com/Ming-Lian" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" style="fill: #222; color: #fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/09/InAction-ML-XGS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lianm">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lianm's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">西瓜书带学训练营·实战任务

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-02-09 00:17:04" itemprop="dateCreated datePublished" datetime="2019-02-09T00:17:04+00:00">2019-02-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-02-24 14:23:38" itemprop="dateModified" datetime="2019-02-24T14:23:38+00:00">2019-02-24</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine-Learning</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-“达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用"><a href="#1-“达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用" class="headerlink" title="1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用"></a>1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用</h2><h3 id="1-1-任务描述"><a href="#1-1-任务描述" class="headerlink" title="1.1. 任务描述"></a>1.1. 任务描述</h3><p>具体任务可以到 <a href="http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html" target="_blank" rel="noopener">‘达观杯’文本智能处理挑战赛官网</a> 查看</p>
<p><strong>任务</strong>：建立模型通过长文本数据正文(article)，预测文本对应的类别(class)</p>
<p>数据：</p>
<blockquote>
<p>数据包含2个csv文件：</p>
<ul>
<li><p><strong>train_set.csv</strong></p>
<p>  此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共有四列：</p>
<p>  第一列是文章的索引(id)，第二列是文章正文在“字”级别上的表示，即字符相隔正文(article)；第三列是在“词”级别上的表示，即词语相隔正文(word_seg)；第四列是这篇文章的标注(class)。</p>
<p>  注：每一个数字对应一个“字”，或“词”，或“标点符号”。“字”的编号与“词”的编号是独立的！</p>
</li>
<li><p><strong>test_set.csv</strong> </p>
<p>  此数据用于测试。数据格式同train_set.csv，但不包含class</p>
<p>  注：test_set与train_test中文章id的编号是独立的。</p>
</li>
</ul>
</blockquote>
<h3 id="1-2-编程实现"><a href="#1-2-编程实现" class="headerlink" title="1.2. 编程实现"></a>1.2. 编程实现</h3><p>使用<strong>logistic回归</strong>来实现这个多元分类任务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.feature_extract.txt import TfidfVectorizer</span><br><span class="line">from sklearn.decomposition import TruncatedSVD</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.model_select import train_test_split</span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">t_start = time.time()</span><br><span class="line"></span><br><span class="line"># ===========================================================</span><br><span class="line"># 1. 载人数据与数据预处理</span><br><span class="line">df_train = pd.read_csv(&apos;data/train_set.csv&apos;)</span><br><span class="line">df_train = df_train.drop(columns=&apos;article&apos;,inplace=True)</span><br><span class="line">df_test = pd.read_csv(&apos;data/test_set.csv&apos;)</span><br><span class="line">df_test = df_test.drop(columns=&apos;article&apos;,inplace=True)</span><br><span class="line">y_train = (df_train[&apos;class&apos;] - 1).values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ===========================================================</span><br><span class="line"># 2. 特征工程，这里先使用经典的文本特征提取方法TFIDF，提取的TFIDF特征</span><br><span class="line">vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, sublinear_tf=True)</span><br><span class="line">vectorizer.fit(df_train[&apos;word_seg&apos;])</span><br><span class="line">X_train = vectorizer.transform(df_train[&apos;word_seg&apos;])</span><br><span class="line">X_test = vectorizer.transform(df_test[&apos;word_seg&apos;])</span><br><span class="line"></span><br><span class="line"># 可以将得到的TFIDF特征保存至本地</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">data = (X_train,y_train,X_test)</span><br><span class="line">f = open(&apos;data/data_tfidf.pkl&apos;,&apos;wb&apos;)</span><br><span class="line">pickle.dump(data,f)</span><br><span class="line">f.close()</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ===========================================================</span><br><span class="line"># 3. 特征降维，将上一步提取的TFIDF特征使用lsa方法进行特征降维</span><br><span class="line">lsa = TruncatedSVD(n_components=200)</span><br><span class="line">X_train = lsa.transform(X_train)</span><br><span class="line">X_test = lsa.transform(X_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ===========================================================</span><br><span class="line"># 4. 训练分类器</span><br><span class="line"></span><br><span class="line"># 划分训练集和验证集</span><br><span class="line">X_train,X_vali,y_train,y_vali = train_test_split(X_train,y_train,test_size=0.1,random_state=0)</span><br><span class="line"></span><br><span class="line">##  multi_class:分类方式选择参数，有&quot;ovr(默认)&quot;和&quot;multinomial&quot;两个值可选择，在二元逻辑回归中无区别</span><br><span class="line">##  solver:优化算法选择参数，当penalty为&quot;l1&quot;时，参数只能是&quot;liblinear(坐标轴下降法)&quot;；&quot;lbfgs&quot;和&quot;cg&quot;都是关于目标函数的二阶泰勒展开</span><br><span class="line">##  当penalty为&quot;l2&quot;时，参数可以是&quot;lbfgs(拟牛顿法)&quot;,&quot;newton_cg(牛顿法变种)&quot;,&quot;seg(minibactch随机平均梯度下降)&quot;</span><br><span class="line">lr = LogisticRegression(multi_class=&quot;ovr&quot;,penalty=&quot;l2&quot;,solver=&quot;lbfgs&quot;)</span><br><span class="line">lr.fit(X_train,y_train)</span><br><span class="line"></span><br><span class="line"># 模型的保存与持久化</span><br><span class="line">joblib.dump(lr,&quot;logistic_lr.model&quot;)</span><br><span class="line">joblib.load(&quot;logistic_lr.model&quot;) #加载模型,会保存该model文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ===========================================================</span><br><span class="line"># 5. 在验证集上评估模型</span><br><span class="line">pre_vali = lr.predict(X_vali)</span><br><span class="line">pre_score = f1_score(y_true=y_vali,y_pred=pre_vali,average=&apos;macro&apos;)</span><br><span class="line">print(&quot;验证集分数：&#123;&#125;&quot;.format(score_vali))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ===========================================================</span><br><span class="line"># 6. 对测试集进行预测</span><br><span class="line">y_test = lr.predict(X_test) + 1</span><br></pre></td></tr></table></figure>
<h3 id="1-3-sklearn包中logistic算法的使用"><a href="#1-3-sklearn包中logistic算法的使用" class="headerlink" title="1.3. sklearn包中logistic算法的使用"></a>1.3. sklearn包中logistic算法的使用</h3><p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-1.png" alt></p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-2.png" alt></p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-3.png" alt></p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-4.png" alt></p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-5.png" alt></p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-6.png" alt></p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-lr-7.png" alt></p>
<h2 id="2-鸢尾花数据分类：sklearn包中决策树算法类库的使用"><a href="#2-鸢尾花数据分类：sklearn包中决策树算法类库的使用" class="headerlink" title="2. 鸢尾花数据分类：sklearn包中决策树算法类库的使用"></a>2. 鸢尾花数据分类：sklearn包中决策树算法类库的使用</h2><h3 id="2-1-DecisionTreeClassifier实例"><a href="#2-1-DecisionTreeClassifier实例" class="headerlink" title="2.1. DecisionTreeClassifier实例"></a>2.1. DecisionTreeClassifier实例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">from itertools import product</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import MinMaxScaler</span><br><span class="line">from sklearn.feature_selection import SelectKBest</span><br><span class="line">from sklearn.feature_selection import chi2</span><br><span class="line">from sklearn.decomposition import PCA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用自带的iris数据</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data[:, np.arange(0,4)]</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"># 划分训练集与测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=14)</span><br><span class="line">print(&quot;训练数据集样本总数:%d;测试数据集样本总数:%d&quot; %(x_train.shape[0],x_test.shape[0]))</span><br><span class="line"></span><br><span class="line"># 对数据集进行标准化</span><br><span class="line">ss = MinMaxScaler()</span><br><span class="line">x_train = ss.fit_transform(x_train,y_train)</span><br><span class="line">x_test = ss.transform(x_test)</span><br><span class="line"></span><br><span class="line"># 特征选择：从已有的特征属性中选择出影响目标最大的特征属性</span><br><span class="line"># 常用方法：</span><br><span class="line">#	离散属性：F统计量、卡方系数、互信息mutual_info_classif</span><br><span class="line">#	连续属性：皮尔逊相关系数、F统计量、互信息mutual_info_classif&#125;</span><br><span class="line"># 这里使用离散属性的卡方系数，实现函数为SelectKBest，用SelectKBest方法从四个原始特征属性中选择出最能影响目标的3个特征属性</span><br><span class="line">ch2 = SelectKBest(chi2,k=3) # k默认为10，指定后会返回想要的特征个数</span><br><span class="line">ch2.fit(x_train,y_train)</span><br><span class="line">x_train = ch2.transform(x_train)</span><br><span class="line">x_test = ch2.transform(x_test)</span><br><span class="line"></span><br><span class="line"># 特征降维，这里使用PCA方法</span><br><span class="line">pca = PCA(n_components=2)   # 构建一个PCA对象，设置最终维度为2维。这里为了后边画图方便，将数据维度设置为 2，一般用默认不设置就可以</span><br><span class="line">x_train = pca.fit_transform(x_train) # 训练与转换，也可以拆分成两步</span><br><span class="line">x_test = pca.transform(x_test)</span><br><span class="line"></span><br><span class="line"># 训练模型</span><br><span class="line">#	criterion：指定特征选择标准，可以使用&quot;gini&quot;或者&quot;entropy&quot;，前者代表基尼系数，后者代表信息增益</span><br><span class="line">#	max_depth：限制树的最大深度4</span><br><span class="line">clf = DecisionTreeClassifier(criterion=&quot;entropy&quot;,max_depth=4)</span><br><span class="line">clf.fit(X, y) # 拟合模型</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 画图</span><br><span class="line">x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1</span><br><span class="line">y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1</span><br><span class="line"># 生成网格采样点</span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),</span><br><span class="line">                     np.arange(y_min, y_max, 0.1))</span><br><span class="line"></span><br><span class="line">Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line">Z = Z.reshape(xx.shape)</span><br><span class="line"></span><br><span class="line">plt.contourf(xx, yy, Z, alpha=0.4)</span><br><span class="line">plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-decision-tree-1.png" alt></p>
<h3 id="2-2-可视化决策树"><a href="#2-2-可视化决策树" class="headerlink" title="2.2. 可视化决策树"></a>2.2. 可视化决策树</h3><p>scikit-learn中决策树的可视化一般需要安装graphviz，主要包括graphviz的安装和python的graphviz插件的安装</p>
<blockquote>
<ul>
<li><p>1) 安装graphviz。下载地址在：<code>http://www.graphviz.org</code>/。如果你是linux，可以用apt-get或者yum的方法安装。如果是windows，就在官网下载msi文件安装。无论是linux还是windows，装完后都要设置环境变量，将graphviz的bin目录加到PATH，比如我是windows，将<code>C:/Program Files (x86)/Graphviz2.38/bin/</code>加入了<code>PATH</code></p>
</li>
<li><p>2) 安装python插件graphviz： <code>pip install graphviz</code></p>
</li>
</ul>
<ul>
<li>3) 安装python插件pydotplus: <code>pip install pydotplus</code></li>
</ul>
</blockquote>
<p>这样环境就搭好了，有时候python会很笨，仍然找不到graphviz，这时，可以在代码里面加入这一行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.environ[&quot;PATH&quot;] += os.pathsep + &apos;C:/Program Files (x86)/Graphviz2.38/bin/&apos;</span><br></pre></td></tr></table></figure>
<p>可视化决策树的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from IPython.display import Image  </span><br><span class="line">from sklearn import tree</span><br><span class="line">import pydotplus </span><br><span class="line">dot_data = tree.export_graphviz(clf, out_file=None, </span><br><span class="line">                         feature_names=iris.feature_names,  </span><br><span class="line">                         class_names=iris.target_names,  </span><br><span class="line">                         filled=True, rounded=True,  </span><br><span class="line">                         special_characters=True)  </span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)  </span><br><span class="line">Image(graph.create_png())</span><br></pre></td></tr></table></figure>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-decision-tree-2.png" alt></p>
<h2 id="3-sklearn中测试数据：sklearn包中SVM算法库的使用"><a href="#3-sklearn中测试数据：sklearn包中SVM算法库的使用" class="headerlink" title="3. sklearn中测试数据：sklearn包中SVM算法库的使用"></a>3. sklearn中测试数据：sklearn包中SVM算法库的使用</h2><h3 id="3-1-SVM相关知识点回顾"><a href="#3-1-SVM相关知识点回顾" class="headerlink" title="3.1. SVM相关知识点回顾"></a>3.1. SVM相关知识点回顾</h3><h4 id="3-1-1-SVM与SVR"><a href="#3-1-1-SVM与SVR" class="headerlink" title="3.1.1. SVM与SVR"></a>3.1.1. SVM与SVR</h4><ul>
<li><p><strong>SVM分类算法</strong></p>
<p>  其原始形式是：</p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-1.png" alt></p>
<p>  其中m为样本个数，我们的样本为(x<sub>1</sub>,y<sub>1</sub>),(x<sub>2</sub>,y<sub>2</sub>),…,(x<sub>m</sub>,y<sub>m</sub>)。w,b是我们的分离超平面的w∙ϕ(x<sub>i</sub>)+b=0系数, ξ<sub>i</sub>为第i个样本的松弛系数， C为惩罚系数。ϕ(x<sub>i</sub>)为低维到高维的映射函数</p>
<p>  通过拉格朗日函数以及对偶化后的形式为：</p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-2.png" alt></p>
</li>
<li><p><strong>SVR回归算法</strong></p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-3.png" alt></p>
<p>  其中m为样本个数，我们的样本为(x<sub>1</sub>,y<sub>1</sub>),(x<sub>2</sub>,y<sub>2</sub>),…,(x<sub>m</sub>,y<sub>m</sub>)。w,b是我们的回归超平面的w∙x<sub>i</sub>+b=0系数, ξ<sup>∨</sup><sub>i</sub>，ξ<sup>∧</sup><sub>i</sub>为第i个样本的松弛系数， C为惩罚系数，ϵ为损失边界，到超平面距离小于ϵ的训练集的点没有损失。ϕ(x<sub>i</sub>)为低维到高维的映射函数。</p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-4.png" alt></p>
</li>
</ul>
<h4 id="3-1-2-核函数"><a href="#3-1-2-核函数" class="headerlink" title="3.1.2. 核函数"></a>3.1.2. 核函数</h4><p>在scikit-learn中，内置的核函数一共有4种：</p>
<ul>
<li><p><strong>线性核函数</strong>（Linear Kernel）表达式为：K(x,z)=x∙z，就是普通的内积</p>
</li>
<li><p><strong>多项式核函数</strong>（Polynomial Kernel）是线性不可分SVM常用的核函数之一，表达式为：K(x,z)=（γx∙z+r)<sup>d</sup> ，其中，γ,r,d都需要自己调参定义</p>
</li>
<li><p><strong>高斯核函数</strong>（Gaussian Kernel），在SVM中也称为径向基核函数（Radial Basis Function,RBF），它是 libsvm 默认的核函数，当然也是 scikit-learn 默认的核函数。表达式为：K(x,z)=exp(−γ||x−z||<sup>2</sup>)， 其中，γ大于0，需要自己调参定义</p>
</li>
<li><p><strong>Sigmoid核函数</strong>（Sigmoid Kernel）也是线性不可分SVM常用的核函数之一，表达式为：K(x,z)=tanh（γx∙z+r)， 其中，γ，r都需要自己调参定义</p>
</li>
</ul>
<p>一般情况下，对非线性数据使用默认的高斯核函数会有比较好的效果，如果你不是SVM调参高手的话，建议使用高斯核来做数据分析。　</p>
<h3 id="3-2-sklearn中SVM相关库的简介"><a href="#3-2-sklearn中SVM相关库的简介" class="headerlink" title="3.2. sklearn中SVM相关库的简介"></a>3.2. sklearn中SVM相关库的简介</h3><p>scikit-learn SVM算法库封装了libsvm 和 liblinear 的实现，仅仅重写了算法了接口部分</p>
<h4 id="3-2-1-分类库与回归库"><a href="#3-2-1-分类库与回归库" class="headerlink" title="3.2.1. 分类库与回归库"></a>3.2.1. 分类库与回归库</h4><ul>
<li><p><strong>分类算法库</strong></p>
<p>  包括SVC， NuSVC，和LinearSVC 3个类</p>
<p>  对于SVC， NuSVC，和LinearSVC 3个分类的类，SVC和 NuSVC差不多，区别仅仅在于对损失的度量方式不同，而LinearSVC从名字就可以看出，他是线性分类，也就是不支持各种低维到高维的核函数，仅仅支持线性核函数，对线性不可分的数据不能使用</p>
</li>
<li><p><strong>回归算法库</strong></p>
<p>  包括SVR， NuSVR，和LinearSVR 3个类</p>
<p>  同样的，对于SVR， NuSVR，和LinearSVR 3个回归的类， SVR和NuSVR差不多，区别也仅仅在于对损失的度量方式不同。LinearSVR是线性回归，只能使用线性核函数</p>
</li>
</ul>
<h4 id="3-2-2-高斯核调参"><a href="#3-2-2-高斯核调参" class="headerlink" title="3.2.2. 高斯核调参"></a>3.2.2. 高斯核调参</h4><h5 id="3-2-2-1-需要调节的参数"><a href="#3-2-2-1-需要调节的参数" class="headerlink" title="3.2.2.1. 需要调节的参数"></a>3.2.2.1. 需要调节的参数</h5><ul>
<li><p><strong>SVM分类模型</strong></p>
<p>  如果是SVM分类模型，这两个超参数分别是<strong>惩罚系数C</strong>和<strong>RBF核函数的系数γ</strong></p>
<p>  <strong>惩罚系数C</strong></p>
<blockquote>
<p>它在优化函数里主要是平衡支持向量的复杂度和误分类率这两者之间的关系，可以理解为正则化系数</p>
<ul>
<li><p>当C比较大时，我们的损失函数也会越大，这意味着我们不愿意放弃比较远的离群点。这样我们会有更加多的支持向量，也就是说支持向量和超平面的模型也会变得越复杂，也容易过拟合</p>
</li>
<li><p>当C比较小时，意味我们不想理那些离群点，会选择较少的样本来做支持向量，最终的支持向量和超平面的模型也会简单</p>
</li>
</ul>
<p>scikit-learn中默认值是1</p>
</blockquote>
<p>  C越大，泛化能力越差，易出现过拟合现象；C越小，泛化能力越好，易出现过欠拟合现象</p>
<p>  <strong>BF核函数的参数γ</strong></p>
<blockquote>
<p>RBF 核函数K(x,z)=exp(−γ||x−z||<sup>2</sup>) γ&gt;0</p>
<p>γ主要定义了单个样本对整个分类超平面的影响</p>
<ul>
<li><p>当γ比较小时，单个样本对整个分类超平面的影响比较小，不容易被选择为支持向量</p>
</li>
<li><p>当γ比较大时，单个样本对整个分类超平面的影响比较大，更容易被选择为支持向量，或者说整个模型的支持向量也会多</p>
</li>
</ul>
<p>scikit-learn中默认值是 <code>1/样本特征数</code></p>
</blockquote>
<p>  γ越大，训练集拟合越好，泛化能力越差，易出现过拟合现象</p>
<p>  如果把惩罚系数C和RBF核函数的系数γ一起看，当C比较大， γ比较大时，我们会有更多的支持向量，我们的模型会比较复杂，容易过拟合一些。如果C比较小 ， γ比较小时，模型会变得简单，支持向量的个数会少</p>
</li>
<li><p><strong>SVM回归模型</strong></p>
<p>  SVM回归模型的RBF核比分类模型要复杂一点，因为此时我们除了惩罚系数C和RBF核函数的系数γ之外，还多了一个<strong>损失距离度量ϵ</strong></p>
<blockquote>
<p>对于损失距离度量ϵ，它决定了样本点到超平面的距离损失</p>
<ul>
<li><p>当 ϵ 比较大时，损失较小，更多的点在损失距离范围之内，而没有损失,模型较简单</p>
</li>
<li><p>当 ϵ 比较小时，损失函数会较大，模型也会变得复杂</p>
</li>
</ul>
<p>scikit-learn中默认值是0.1</p>
</blockquote>
<p>  如果把惩罚系数C，RBF核函数的系数γ和损失距离度量ϵ一起看，当C比较大， γ比较大，ϵ比较小时，我们会有更多的支持向量，我们的模型会比较复杂，容易过拟合一些。如果C比较小 ， γ比较小，ϵ比较大时，模型会变得简单，支持向量的个数会少</p>
</li>
</ul>
<h5 id="3-2-2-2-调参方法：网格搜索"><a href="#3-2-2-2-调参方法：网格搜索" class="headerlink" title="3.2.2.2. 调参方法：网格搜索"></a>3.2.2.2. 调参方法：网格搜索</h5><p>对于SVM的RBF核，我们主要的调参方法都是交叉验证。具体在scikit-learn中，主要是使用网格搜索，即GridSearchCV类</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">grid = GridSearchCV(SVC(), param_grid=&#123;&quot;C&quot;:[0.1, 1, 10], &quot;gamma&quot;: [1, 0.1, 0.01]&#125;, cv=4)</span><br><span class="line">grid.fit(X, y)</span><br></pre></td></tr></table></figure>
<p>将GridSearchCV类用于SVM RBF调参时要注意的参数有：</p>
<blockquote>
<p>1) <strong>estimator</strong>：即我们的模型，此处我们就是带高斯核的SVC或者SVR</p>
<p>2) <strong>param_grid</strong>：即我们要调参的参数列表。 比如我们用SVC分类模型的话，那么param_grid可以定义为{“C”:[0.1, 1, 10], “gamma”: [0.1, 0.2, 0.3]}，这样我们就会有9种超参数的组合来进行网格搜索，选择一个拟合分数最好的超平面系数</p>
<p>3) <strong>cv</strong>：S折交叉验证的折数，即将训练集分成多少份来进行交叉验证。默认是3。如果样本较多的话，可以适度增大cv的值</p>
</blockquote>
<h3 id="3-3-编程实现"><a href="#3-3-编程实现" class="headerlink" title="3.3. 编程实现"></a>3.3. 编程实现</h3><ol>
<li><p>生成测试数据</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import make_circles</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line"># 生成一些随机数据用于后续分类</span><br><span class="line">X, y = make_circles(noise=0.2, factor=0.5, random_state=1) # 生成时加入了一些噪声</span><br><span class="line">X = StandardScaler().fit_transform(X) # 把数据归一化</span><br></pre></td></tr></table></figure>
</li>
</ol>
<pre><code>生成的随机数据可视化结果如下：
</code></pre><p><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-5.png" alt></p>
<ol start="2">
<li><p>调参</p>
<p> 接着采用网格搜索的策略进行RBF核函数参数搜索</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">grid = GridSearchCV(SVC(), param_grid=&#123;&quot;C&quot;:[0.1, 1, 10], &quot;gamma&quot;: [1, 0.1, 0.01]&#125;, cv=4) # 总共有9种参数组合的搜索空间</span><br><span class="line">grid.fit(X, y)</span><br><span class="line">print(&quot;The best parameters are %s with a score of %0.2f&quot;</span><br><span class="line">      % (grid.best_params_, grid.best_score_))</span><br><span class="line"></span><br><span class="line">输出为：</span><br><span class="line">The best parameters are &#123;&apos;C&apos;: 10, &apos;gamma&apos;: 0.1&#125; with a score of 0.91</span><br></pre></td></tr></table></figure>
<p> 可以对9种参数组合训练的结果进行可视化，观察分类的效果：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1</span><br><span class="line">y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1</span><br><span class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max,0.02),</span><br><span class="line">                     np.arange(y_min, y_max, 0.02))</span><br><span class="line"></span><br><span class="line">for i, C in enumerate((0.1, 1, 10)):</span><br><span class="line">    for j, gamma in enumerate((1, 0.1, 0.01)):</span><br><span class="line">        plt.subplot()       </span><br><span class="line">        clf = SVC(C=C, gamma=gamma)</span><br><span class="line">        clf.fit(X,y)</span><br><span class="line">        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])</span><br><span class="line"></span><br><span class="line">        # Put the result into a color plot</span><br><span class="line">        Z = Z.reshape(xx.shape)</span><br><span class="line">        plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)</span><br><span class="line"></span><br><span class="line">        # Plot also the training points</span><br><span class="line">        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)</span><br><span class="line"></span><br><span class="line">        plt.xlim(xx.min(), xx.max())</span><br><span class="line">        plt.ylim(yy.min(), yy.max())</span><br><span class="line">        plt.xticks(())</span><br><span class="line">        plt.yticks(())</span><br><span class="line">        plt.xlabel(&quot; gamma=&quot; + str(gamma) + &quot; C=&quot; + str(C))</span><br><span class="line">        plt.show()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:center"><code>C \ gamma</code></th>
<th style="text-align:center">1</th>
<th style="text-align:center">0.1</th>
<th style="text-align:center">0.001</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0.1</td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-6.png" alt></td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-7.png" alt></td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-8.png" alt></td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-9.png" alt></td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-10.png" alt></td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-11.png" alt></td>
</tr>
<tr>
<td style="text-align:center">10</td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-12.png" alt></td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-13.png" alt></td>
<td style="text-align:center"><img src="/images/InAction-MachineLearning-XGS-sklearn-SVM-14.png" alt></td>
</tr>
</tbody>
</table>
<h2 id="4-sklearn包中朴素贝叶斯库的使用"><a href="#4-sklearn包中朴素贝叶斯库的使用" class="headerlink" title="4.sklearn包中朴素贝叶斯库的使用"></a>4.sklearn包中朴素贝叶斯库的使用</h2><h3 id="4-1-朴素贝叶斯相关知识点回顾"><a href="#4-1-朴素贝叶斯相关知识点回顾" class="headerlink" title="4.1. 朴素贝叶斯相关知识点回顾"></a>4.1. 朴素贝叶斯相关知识点回顾</h3><h4 id="4-1-1-什么是朴素贝叶斯分类器"><a href="#4-1-1-什么是朴素贝叶斯分类器" class="headerlink" title="4.1.1. 什么是朴素贝叶斯分类器"></a>4.1.1. 什么是朴素贝叶斯分类器</h4><p>判别式模型（discriminative models)：像决策树、BP神经网络、支持向量机等，都可以归入判别式模型，它们都是直接学习出输出Y与特征X的关系，如：</p>
<ul>
<li>决策函数 Y=f(X)</li>
<li>条件概率 P(Y|X)</li>
</ul>
<p>生成式模型 (gernerative models)：先对联合概率分布 P(X,Y) 进行建模，然后再由此获得P(Y|X) = P(X,Y)/P(X)</p>
<p>贝叶斯学派的思想：</p>
<blockquote>
<p>贝叶斯学派的思想可以概括为先验概率+数据=后验概率。也就是说我们在实际问题中需要得到的后验概率，可以通过先验概率和数据一起综合得到。数据大家好理解，被频率学派攻击的是先验概率，一般来说先验概率就是我们对于数据所在领域的历史经验，但是这个经验常常难以量化或者模型化，于是贝叶斯学派大胆的假设先验分布的模型，比如正态分布，beta分布等。这个假设一般没有特定的依据，因此一直被频率学派认为很荒谬。虽然难以从严密的数学逻辑里推出贝叶斯学派的逻辑，但是在很多实际应用中，贝叶斯理论很好用，比如垃圾邮件分类，文本分类</p>
</blockquote>
<p>如何对P(X,Y)进行建模？</p>
<blockquote>
<p>假如我们的分类模型样本是：</p>
<p>(x<sup>(1)</sup><sub>1</sub>,x<sup>(1)</sup><sub>2</sub>,…x<sup>(1)</sup><sub>n</sub>,y<sub>1</sub>), (x<sup>(2)</sup><sub>1</sub>,x<sup>(2)</sup><sub>2</sub>,…x<sup>(2)</sup><sub>n</sub>,y<sub>2</sub>),…(x<sup>(m)</sup><sub>1</sub>,x<sup>(m)</sup><sub>2</sub>, …, x<sup>(m)</sup><sub>n</sub>,y<sub>m</sub>)</p>
<p>则</p>
<p>P(X, Y) = P(Y) * P( X = (x<sub>1</sub>, x<sub>2</sub>, …, x<sub>n</sub>) | Y ) </p>
<p>其中</p>
<p>P( X = (x<sub>1</sub>, x<sub>2</sub>, …, x<sub>n</sub>) | Y )  =  P( x<sub>1</sub> | Y) * P( x<sub>2</sub> | Y, x<sub>1</sub>) * … P( x<sub>n</sub> | Y, x<sub>1</sub>, … , x<sub>n-1</sub>)</p>
</blockquote>
<p>这是一个超级复杂的有n个维度的条件分布，很难求出</p>
<p>朴素贝叶斯模型在这里做了一个大胆的假设，即X的n个维度之间相互独立，这样就可以得出：</p>
<p>P( X = (x<sub>1</sub>, x<sub>2</sub>, …, x<sub>n</sub>) | Y ) = P( x<sub>1</sub> | Y) * P( x<sub>2</sub> | Y) * … * P( x<sub>n</sub> | Y) </p>
<h4 id="4-1-2-朴素贝叶斯推断"><a href="#4-1-2-朴素贝叶斯推断" class="headerlink" title="4.1.2. 朴素贝叶斯推断"></a>4.1.2. 朴素贝叶斯推断</h4><p><img src="/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-1.png" alt></p>
<h4 id="4-1-3-朴素贝叶斯学习"><a href="#4-1-3-朴素贝叶斯学习" class="headerlink" title="4.1.3. 朴素贝叶斯学习"></a>4.1.3. 朴素贝叶斯学习</h4><p>需要从训练样本中学习到以下两个参数：</p>
<ul>
<li><p><strong>先验概率</strong> P(c)</p>
<p>  P(c)表示了样本空间中各类样本所占的比例</p>
<p>  根据大数定律，当训练集中包含充足的独立同分布样本时，P(c)可根据各类样本出现的频率来估计</p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-2.png" alt></p>
</li>
<li><p><strong>类条件概率</strong>（又称为似然） P(x<sub>i</sub> | c)</p>
<p>  （1）如果 x<sub>i</sub> 是离散的，可以假设 x<sub>i</sub>符合多项式分布，这样得到 P(x<sub>i</sub> | c) 是在样本类别 c 中，特征 x<sub>i</sub> 出现的频率</p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-3.png" alt></p>
<p>  （2）如果 x<sub>i</sub> 是连续属性，可以假设 P(x<sub>i</sub> | c) ~ N( μ<sub>c,i</sub> , σ<sup>2</sup><sub>c,i</sub> )</p>
<p>  <img src="/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-4.png" alt></p>
</li>
</ul>
<h3 id="4-2-sklearn中朴素贝叶斯类库的简介"><a href="#4-2-sklearn中朴素贝叶斯类库的简介" class="headerlink" title="4.2. sklearn中朴素贝叶斯类库的简介"></a>4.2. sklearn中朴素贝叶斯类库的简介</h3><p>在scikit-learn中，一共有3个朴素贝叶斯的分类算法类</p>
<blockquote>
<ul>
<li><p>GaussianNB：先验为高斯分布的朴素贝叶斯</p>
</li>
<li><p>MultinomialNB：先验为多项式分布的朴素贝叶斯</p>
</li>
<li><p>BernoulliNB：先验为伯努利分布的朴素贝叶斯</p>
</li>
</ul>
</blockquote>
<p>这三个类适用的分类场景各不相同</p>
<blockquote>
<p>一般来说，如果样本特征的分布大部分是<strong>连续值</strong>，使用GaussianNB会比较好</p>
<p>如果如果样本特征的分大部分是<strong>多元离散值</strong>，使用MultinomialNB比较合适</p>
<p>如果样本特征是<strong>二元离散值</strong>或者<strong>很稀疏的多元离散值</strong>，应该使用BernoulliNB。</p>
</blockquote>
<h4 id="4-2-1-GaussianNB类"><a href="#4-2-1-GaussianNB类" class="headerlink" title="4.2.1. GaussianNB类"></a>4.2.1. GaussianNB类</h4><p>GaussianNB类的主要参数仅有一个，即先验概率priors</p>
<p>这个值默认不给出，如果不给出此时P(Y=c)= m<sub>c</sub> / m，如果给出的话就以priors 为准</p>
<p>在使用GaussianNB的fit方法拟合数据后，我们可以进行预测。此时预测有三种方法</p>
<blockquote>
<ul>
<li><p>predict方法：就是我们最常用的预测方法，直接给出测试集的预测类别输出；</p>
</li>
<li><p>predict_proba方法：给出测试集样本在各个类别上预测的概率；</p>
</li>
<li><p>predict_log_proba方法：和predict_proba类似，它会给出测试集样本在各个类别上预测的概率的一个对数转化；</p>
</li>
</ul>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line"></span><br><span class="line">clf = GaussianNB()</span><br><span class="line">#拟合数据</span><br><span class="line">clf.fit(X, Y)</span><br><span class="line"></span><br><span class="line">#进行预测</span><br><span class="line">clf.predict([[-0.8, -1]])</span><br></pre></td></tr></table></figure>
<h4 id="4-2-2-MultinomialNB类"><a href="#4-2-2-MultinomialNB类" class="headerlink" title="4.2.2. MultinomialNB类"></a>4.2.2. MultinomialNB类</h4><p>MultinomialNB假设特征的先验概率为多项式分布，即如下式：</p>
<p><img src="/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-5.png" alt></p>
<p>MultinomialNB参数比GaussianNB多，但是一共也只有仅仅3个</p>
<ul>
<li><p><strong>参数alpha</strong>：为上面的常数λ。如果你没有特别的需要，用默认的1即可。如果发现拟合的不好，需要调优时，可以选择稍大于1或者稍小于1的数</p>
</li>
<li><p><strong>参数fit_prior</strong>：是否要考虑先验概率，如果是false，则所有的样本类别输出都有相同的类别先验概率；否则可以自己用第三个参数class_prior输入先验概率，或者不输入第三个参数class_prior让MultinomialNB自己从训练集样本来计算先验概率</p>
</li>
<li><p><strong>参数class_prior</strong>：输入先验概率，若不输入第三个参数class_prior让MultinomialNB自己从训练集样本来计算先验概率</p>
</li>
</ul>
<h4 id="4-2-3-BernoulliNB类"><a href="#4-2-3-BernoulliNB类" class="headerlink" title="4.2.3. BernoulliNB类"></a>4.2.3. BernoulliNB类</h4><p><img src="/images/InAction-MachineLearning-XGS-sklearn-naive-bayes-6.png" alt></p>
<p>其中，x <sub>i</sub> 只能取0或1</p>
<p>BernoulliNB一共有4个参数，其中3个参数的名字和意义和MultinomialNB完全相同</p>
<p>唯一增加的一个参数是binarize，这个参数主要是用来帮BernoulliNB处理二项分布的。如果不输入，则BernoulliNB认为每个数据特征都已经是二元的。否则的话，小于binarize的会归为一类，大于binarize的会归为另外一类</p>
<hr>
<p>参考资料：</p>
<p>(1) <a href="https://github.com/MLjian/TextClassificationImplement" target="_blank" rel="noopener">【GitHub】MLjian/TextClassificationImplement</a></p>
<p>(2) <a href="https://www.cnblogs.com/pinard/p/6035872.html" target="_blank" rel="noopener">刘建平Pinard《scikit-learn 逻辑回归类库使用小结》</a></p>
<p>(3) <a href="https://blog.csdn.net/loveliuzz/article/details/78708359" target="_blank" rel="noopener">loveliuzz《机器学习sklearn19.0——Logistic回归算法》</a></p>
<p>(4) <a href="https://www.cnblogs.com/pinard/p/6056319.html" target="_blank" rel="noopener">刘建平Pinard《scikit-learn决策树算法类库使用小结》</a></p>
<p>(5) <a href="https://blog.csdn.net/loveliuzz/article/details/78739438" target="_blank" rel="noopener">loveliuzz《机器学习sklearn19.0——决策树算法》</a></p>
<p>(6) <a href="https://www.cnblogs.com/pinard/p/6117515.html" target="_blank" rel="noopener">刘建平Pinard《scikit-learn 支持向量机算法库使用小结》</a></p>
<p>(7) <a href="https://www.cnblogs.com/pinard/p/6126077.html" target="_blank" rel="noopener">刘建平Pinard《支持向量机高斯核调参小结》</a></p>
<p>(8) <a href="https://blog.csdn.net/loveliuzz/article/details/78768063" target="_blank" rel="noopener">loveliuzz《机器学习sklearn19.0——SVM算法》</a></p>
<p>(9) 周志华《机器学习》</p>
<p>(10) <a href="https://www.cnblogs.com/pinard/p/6069267.html" target="_blank" rel="noopener">刘建平Pinard《朴素贝叶斯算法原理小结》</a></p>
<p>(11) <a href="https://www.cnblogs.com/pinard/p/6074222.html" target="_blank" rel="noopener">刘建平Pinard《scikit-learn 朴素贝叶斯类库使用小结》</a></p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/sklearn/" rel="tag"># sklearn</a>
          
            <a href="/tags/logistic回归/" rel="tag"># logistic回归</a>
          
            <a href="/tags/决策树/" rel="tag"># 决策树</a>
          
            <a href="/tags/朴素贝叶斯方法/" rel="tag"># 朴素贝叶斯方法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/02/09/Helpdoc-for-different-languages/" rel="next" title="在Perl、Shell和Python中传参与输出帮助文档">
                <i class="fa fa-chevron-left"></i> 在Perl、Shell和Python中传参与输出帮助文档
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/02/09/Load-and-resolve-MarkdownDoc/" rel="prev" title="前端小技巧：加载并解析Markdown文档">
                前端小技巧：加载并解析Markdown文档 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Lianm</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">14</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">21</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/Ming-Lian" title="GitHub &rarr; https://github.com/Ming-Lian" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:lianming17m@big.ac.cn" title="E-Mail &rarr; mailto:lianming17m@big.ac.cn" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-“达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用"><span class="nav-number">1.</span> <span class="nav-text">1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-任务描述"><span class="nav-number">1.1.</span> <span class="nav-text">1.1. 任务描述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-编程实现"><span class="nav-number">1.2.</span> <span class="nav-text">1.2. 编程实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-sklearn包中logistic算法的使用"><span class="nav-number">1.3.</span> <span class="nav-text">1.3. sklearn包中logistic算法的使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-鸢尾花数据分类：sklearn包中决策树算法类库的使用"><span class="nav-number">2.</span> <span class="nav-text">2. 鸢尾花数据分类：sklearn包中决策树算法类库的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-DecisionTreeClassifier实例"><span class="nav-number">2.1.</span> <span class="nav-text">2.1. DecisionTreeClassifier实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-可视化决策树"><span class="nav-number">2.2.</span> <span class="nav-text">2.2. 可视化决策树</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-sklearn中测试数据：sklearn包中SVM算法库的使用"><span class="nav-number">3.</span> <span class="nav-text">3. sklearn中测试数据：sklearn包中SVM算法库的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-SVM相关知识点回顾"><span class="nav-number">3.1.</span> <span class="nav-text">3.1. SVM相关知识点回顾</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-SVM与SVR"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1. SVM与SVR</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-核函数"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.2. 核函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-sklearn中SVM相关库的简介"><span class="nav-number">3.2.</span> <span class="nav-text">3.2. sklearn中SVM相关库的简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-1-分类库与回归库"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1. 分类库与回归库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-2-高斯核调参"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2. 高斯核调参</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-2-1-需要调节的参数"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">3.2.2.1. 需要调节的参数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-2-2-2-调参方法：网格搜索"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">3.2.2.2. 调参方法：网格搜索</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-编程实现"><span class="nav-number">3.3.</span> <span class="nav-text">3.3. 编程实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-sklearn包中朴素贝叶斯库的使用"><span class="nav-number">4.</span> <span class="nav-text">4.sklearn包中朴素贝叶斯库的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-朴素贝叶斯相关知识点回顾"><span class="nav-number">4.1.</span> <span class="nav-text">4.1. 朴素贝叶斯相关知识点回顾</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-1-什么是朴素贝叶斯分类器"><span class="nav-number">4.1.1.</span> <span class="nav-text">4.1.1. 什么是朴素贝叶斯分类器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-2-朴素贝叶斯推断"><span class="nav-number">4.1.2.</span> <span class="nav-text">4.1.2. 朴素贝叶斯推断</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-3-朴素贝叶斯学习"><span class="nav-number">4.1.3.</span> <span class="nav-text">4.1.3. 朴素贝叶斯学习</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-sklearn中朴素贝叶斯类库的简介"><span class="nav-number">4.2.</span> <span class="nav-text">4.2. sklearn中朴素贝叶斯类库的简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-1-GaussianNB类"><span class="nav-number">4.2.1.</span> <span class="nav-text">4.2.1. GaussianNB类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-2-MultinomialNB类"><span class="nav-number">4.2.2.</span> <span class="nav-text">4.2.2. MultinomialNB类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-BernoulliNB类"><span class="nav-number">4.2.3.</span> <span class="nav-text">4.2.3. BernoulliNB类</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lianm</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.0.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=7.0.0"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>



  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
